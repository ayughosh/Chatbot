{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631f5911-9672-46cb-8cd6-6132ccbc5c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# batch_size = args.batch_size # to use the batch_size cmd arg -> python file_name.py -batch_size 32\n",
    "batch_size = 128\n",
    "#block_size = 64\n",
    "max_iters = 10\n",
    "learning_rate = 3e-3\n",
    "eval_iters = 2\n",
    "eval_interval=500\n",
    "n_embd = 384\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338b1cae-06b6-40b8-92ac-ccd8ce634c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in d:\\python_testing\\cuda\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in d:\\python_testing\\cuda\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in d:\\python_testing\\cuda\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in d:\\python_testing\\cuda\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in d:\\python_testing\\cuda\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python_testing\\cuda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python_testing\\cuda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python_testing\\cuda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python_testing\\cuda\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc54d088-d45c-41fe-96d2-789fb14685cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\python_testing\\cuda\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python_testing\\cuda\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python_testing\\cuda\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python_testing\\cuda\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python_testing\\cuda\\lib\\site-packages (from requests) (3.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b18bc9-8922-4322-a222-62ed542ba6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments extracted and saved to comments.json\n"
     ]
    }
   ],
   "source": [
    "# Set up your Reddit API credentials\n",
    "import praw\n",
    "import json\n",
    "reddit = praw.Reddit(\n",
    "    client_id='_aAnJg3YfIZqHteF_Gx4vg',\n",
    "    client_secret='O6kpd18vcDpmo7JcZEPhyXGjgEIgUA',\n",
    "    user_agent='My_Bot/0.1 by u/Fuzzy_Bookkeeper_118'\n",
    ")\n",
    "\n",
    "# Specify the URL of the Reddit post\n",
    "url = 'https://www.reddit.com/r/SaaS/comments/1ho8qvx/ai_agents_are_they_the_future_or_just_hype/'\n",
    "\n",
    "# Fetch the submission\n",
    "submission = reddit.submission(url=url)\n",
    "\n",
    "# Extract comments\n",
    "comments = []\n",
    "submission.comments.replace_more(limit=None)\n",
    "for comment in submission.comments.list():\n",
    "    comments.append(comment.body)\n",
    "\n",
    "# Save comments to a JSON file\n",
    "with open('comments.json', 'w') as f:\n",
    "    json.dump(comments, f, indent=4)\n",
    "\n",
    "print(\"Comments extracted and saved to comments.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26e7f1fb-2f61-4955-bf22-e45b8c74e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "# Load the extracted comments\n",
    "with open('comments.json', 'r') as f:\n",
    "    comments = json.load(f)\n",
    "\n",
    "# Create a single string of text\n",
    "text = ' '.join(comments)\n",
    "\n",
    "# Create the vocabulary and encoding functions\n",
    "chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)  \n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcb8dc9-e941-4013-b8b7-4f774e343ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary saved to vocab.txt\n",
      "Encoded data saved to encoded_data.bin\n",
      "Memory mapping successful\n",
      "Dataset loaded\n",
      "Temporary directory cleaned up\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "string_to_int={ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string={i:ch for i,ch in enumerate(chars)}\n",
    "encode=lambda s:[string_to_int[c] for c in s]\n",
    "decode=lambda l:' '.join([int_to_string[i] for i in l])\n",
    "\n",
    "# Save vocabulary to vocab.txt\n",
    "with open('vocab.txt', 'w') as f:\n",
    "    for ch in chars:\n",
    "        f.write(f\"{ch}\\t{string_to_int[ch]}\\n\")\n",
    "print(\"Vocabulary saved to vocab.txt\")\n",
    "\n",
    "# Encode the text data\n",
    "encoded_data = encode(text)\n",
    "# Use a temporary directory\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    encoded_data_file = os.path.join(tmpdir, 'encoded_data.bin')\n",
    "\n",
    "    # Save encoded data to a binary file using memory mapping\n",
    "    try:\n",
    "        with open(encoded_data_file, 'wb') as f:\n",
    "            f.write(bytearray(encoded_data))\n",
    "        print(\"Encoded data saved to encoded_data.bin\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error saving encoded data: {e}\")\n",
    "\n",
    "    # Memory map the binary file\n",
    "    try:\n",
    "        with open(encoded_data_file, 'r+b') as f:\n",
    "            data = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "        print(\"Memory mapping successful\")\n",
    "\n",
    "        # Convert the memory-mapped data to a tensor\n",
    "        try:\n",
    "            data_tensor = torch.tensor(list(data), dtype=torch.long)\n",
    "            print(\"Dataset loaded\")  # After loading dataset\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting to tensor: {e}\")\n",
    "        finally:\n",
    "            data.close()  # Close the memory-mapped file\n",
    "    except OSError as e:\n",
    "        print(f\"Error with memory mapping: {e}\")\n",
    "\n",
    "print(\"Temporary directory cleaned up\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b17fc2d-cdcc-4bef-aa47-3cb9b950b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Calculate data length and max block size\n",
    "data_len = len(data_tensor)  # Example: data_len = 10000\n",
    "max_block_size = data_len // batch_size  # Example: max_block_size = 78\n",
    "            \n",
    "# Set block size to a suitable value\n",
    "block_size = min(64, max_block_size)  # Use 64 or max_block_size, whichever is smaller\n",
    "\n",
    "n = int(0.8 * len(data_tensor))\n",
    "train_data = data_tensor[:n]\n",
    "val_data = data_tensor[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    if len(data) < block_size * batch_size:\n",
    "        raise ValueError(\"Data size is smaller than the required block size.\")\n",
    "    \n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
    "    \n",
    "    x, y = x.to(device), y.to(device)\n",
    "    x = x.squeeze(-1)  # Remove the last dimension if it is 1\n",
    "    y = y.squeeze(-1)  # Remove the last dimension if it is 1\n",
    "    print(f\"x shape: {x.shape}, y shape: {y.shape}\")  # Debugging print statement\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3a9459-3c53-4ee0-ba2c-396936672afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized\n"
     ]
    }
   ],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "# [1, 0, 0]\n",
    "# [1, 0.6, 0]\n",
    "# [1, 0.6, 0.4]\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "\n",
    "\n",
    "         \n",
    "#Normalization: Takes place in the __init__ method with self.ln_f = nn.LayerNorm(n_embd), and is applied at the end of the blocks in the transformer architecture.\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table=nn.Embedding(vocab_size, n_embd) #Maps each token in the vocabulary to a dense vector of size n_embd.\n",
    "        self.position_embedding_table= nn.Embedding(block_size, n_embd) #Maps each position in the input sequence to a dense vector of size n_embd\n",
    "        self.blocks=nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)]) #A sequence of transformer blocks (Block),\n",
    "        #each consisting of multi-head self-attention and feed-forward layers\n",
    "\n",
    "        self.ln_f=nn.LayerNorm(n_embd) #final layer norm,Applies layer normalization to stabilize and speed up training.\n",
    "        self.lm_head=nn.Linear(n_embd, vocab_size) #language modelling head, doing the final linear transformation, \n",
    "        #A linear layer that maps the final hidden states to the vocabulary size, used to predict the next token.\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "    def forward(self, index, targets=None):  #Computes the output of the model given an input sequence of token indices. If targets are provided, it also computes the loss.\n",
    "        #logits=self.token_embedding_table(index)  \n",
    "        print(f\"index shape: {index.shape}\")  # Debugging print statement\n",
    "        B, T=index.shape\n",
    "        \n",
    "        #Converts the input token indices (index) into embedding vectors using the token embedding table\n",
    "\n",
    "        #idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb =self.token_embedding_table(index)  #Embeds the token indices (idx), converting them into corresponding embedding vectors.\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) #(T,C) Generates positional encodings for each position in the sequence, ensuring the model can understand the order of tokens.\n",
    "        x = tok_emb + pos_emb #(B,T,C)Adds the token embeddings and positional embeddings element-wise to create a combined representation of tokens with their respective positions.\n",
    "        x = self.blocks(x) #(B, T, C)Passes the combined embeddings through the transformer blocks, \n",
    "        #applying attention mechanisms and other transformations to capture relationships between tokens\n",
    "        x = self.ln_f(x) #(B,T,C)Applies layer normalization to the transformed embeddings, helping stabilize and improve the training process.\n",
    "        logits = self.lm_head(x) #(B,T, vocab_size)\n",
    "        #Passes the normalized embeddings through the final layer (language model head) to produce the logits, which represent the model's raw output before applying any activation functions.\n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            B, T, C=logits.shape#If targets are provided, reshapes the logits and targets tensors, and computes the cross-entropy loss.\n",
    "            logits=logits.view(B*T, C)\n",
    "            targets=targets.view(B*T)\n",
    "            loss=F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits,loss\n",
    "#Decoding: The generate method is responsible for decoding, as it generates new token indices based on the model's predictions.\n",
    "    def generate(self, index, max_new_tokens):  #Generates a sequence of tokens given an initial input context by sampling from the model's predictions.\n",
    "        #index is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            #get the predictions\n",
    "            logits, loss=self.forward(index)\n",
    "            #focus only on the last time step\n",
    "            logits=logits[:, -1, :] #(B,C)   # focus only on the last time step \n",
    "            #apply softmax to get probabilities\n",
    "            #Softmax: Implemented in the generate method using F.softmax(logits, dim=-1) to convert logits to probabilities.\n",
    "            probs=F.softmax(logits, dim=-1)  # apply softmax to get probabilities, converts logits to probabilities\n",
    "            #sample from distribution\n",
    "            index_next=torch.multinomial(probs, num_samples=1) #(B,1) )  # sample the next token index from probability distribution\n",
    "            #append sampled index to the running sequence\n",
    "            index= torch.cat((index, index_next), dim=1) #(B, T+1) # append sampled index to the running sequence\n",
    "        return index\n",
    "\n",
    "model=GPTLanguageModel(vocab_size)\n",
    "print(\"Model initialized\")  # After initializing the model\n",
    "m=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eece93d5-a1f9-43ba-a6dc-6ef463ee6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9321db6f-3e25-4bf4-8075-ae66bc123332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data size is smaller than the required block size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Debugging print statement\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m eval_iters \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m----> 7\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# sample a batch of data\u001b[39;00m\n",
      "File \u001b[1;32mD:\\python_testing\\cuda\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m, in \u001b[0;36mestimate_loss\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m losses \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(eval_iters)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(eval_iters):\n\u001b[1;32m----> 8\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m model(X, Y)\n\u001b[0;32m     10\u001b[0m     losses[k] \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mget_batch\u001b[1;34m(split)\u001b[0m\n\u001b[0;32m     13\u001b[0m data \u001b[38;5;241m=\u001b[39m train_data \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m val_data\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m block_size \u001b[38;5;241m*\u001b[39m batch_size:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData size is smaller than the required block size.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m ix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m block_size, (batch_size,))\n\u001b[0;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[i:i \u001b[38;5;241m+\u001b[39m block_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n",
      "\u001b[1;31mValueError\u001b[0m: Data size is smaller than the required block size."
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    print(f\"Iteration: {iter}\")  # Debugging print statement\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    \n",
    "    print(f\"Loss: {loss.item()}\")  # Debugging print statement\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da447422-a43f-4ac2-9db2-78b2eea25da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index shape: torch.Size([1, 22])\n",
      "index shape: torch.Size([1, 23])\n",
      "index shape: torch.Size([1, 24])\n",
      "index shape: torch.Size([1, 25])\n",
      "index shape: torch.Size([1, 26])\n",
      "index shape: torch.Size([1, 27])\n",
      "index shape: torch.Size([1, 28])\n",
      "index shape: torch.Size([1, 29])\n",
      "index shape: torch.Size([1, 30])\n",
      "index shape: torch.Size([1, 31])\n",
      "index shape: torch.Size([1, 32])\n",
      "index shape: torch.Size([1, 33])\n",
      "index shape: torch.Size([1, 34])\n",
      "index shape: torch.Size([1, 35])\n",
      "index shape: torch.Size([1, 36])\n",
      "index shape: torch.Size([1, 37])\n",
      "index shape: torch.Size([1, 38])\n",
      "index shape: torch.Size([1, 39])\n",
      "index shape: torch.Size([1, 40])\n",
      "index shape: torch.Size([1, 41])\n",
      "index shape: torch.Size([1, 42])\n",
      "index shape: torch.Size([1, 43])\n",
      "index shape: torch.Size([1, 44])\n",
      "index shape: torch.Size([1, 45])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (44) must match the size of tensor b (45) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHello! Can you see me?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encode(prompt), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m----> 3\u001b[0m generated_chars \u001b[38;5;241m=\u001b[39m decode(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_chars)\n",
      "Cell \u001b[1;32mIn[8], line 137\u001b[0m, in \u001b[0;36mGPTLanguageModel.generate\u001b[1;34m(self, index, max_new_tokens)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, index, max_new_tokens):  \u001b[38;5;66;03m#Generates a sequence of tokens given an initial input context by sampling from the model's predictions.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m#index is (B,T) array of indices in the current context\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_new_tokens):\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;66;03m#get the predictions\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m         logits, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;66;03m#focus only on the last time step\u001b[39;00m\n\u001b[0;32m    139\u001b[0m         logits\u001b[38;5;241m=\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m#(B,C)   # focus only on the last time step \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 118\u001b[0m, in \u001b[0;36mGPTLanguageModel.forward\u001b[1;34m(self, index, targets)\u001b[0m\n\u001b[0;32m    116\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m#(T,C) Generates positional encodings for each position in the sequence, ensuring the model can understand the order of tokens.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m#(B,T,C)Adds the token embeddings and positional embeddings element-wise to create a combined representation of tokens with their respective positions.\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#(B, T, C)Passes the combined embeddings through the transformer blocks, \u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m#applying attention mechanisms and other transformations to capture relationships between tokens\u001b[39;00m\n\u001b[0;32m    120\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(x) \u001b[38;5;66;03m#(B,T,C)Applies layer normalization to the transformed embeddings, helping stabilize and improve the training process.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\python_testing\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\python_testing\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\python_testing\\cuda\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\python_testing\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\python_testing\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[8], line 75\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 75\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(x \u001b[38;5;241m+\u001b[39m y)\n\u001b[0;32m     77\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffwd(x)\n",
      "File \u001b[1;32mD:\\python_testing\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\python_testing\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[8], line 43\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 43\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h(x) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[1;32mIn[8], line 43\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 43\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mD:\\python_testing\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\python_testing\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m, in \u001b[0;36mHead.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# compute attention scores (\"affinities\")\u001b[39;00m\n\u001b[0;32m     20\u001b[0m wei \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m k\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;66;03m# (B, T, hs) @ (B, hs, T) -> (B, T, T)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m wei \u001b[38;5;241m=\u001b[39m \u001b[43mwei\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtril\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-inf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, T, T)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m wei \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(wei, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (B, T, T)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m wei \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(wei)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (44) must match the size of tensor b (45) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "prompt = 'Hello! Can you see me?'\n",
    "context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=100)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96247c2-e659-4fba-957e-d2728e1928e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
